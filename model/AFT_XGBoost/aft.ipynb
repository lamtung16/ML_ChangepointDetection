{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'previous'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../../training_data'\n",
    "datasets = ['cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_2456\\1802172062.py:46: RuntimeWarning: overflow encountered in exp\n",
      "  y_upper_bound = np.exp(target_df_train['max.log.lambda'].to_numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aft-nloglik:1.26991+0.06233\ttest-aft-nloglik:1.27391+0.06344\n",
      "[100]\ttrain-aft-nloglik:0.55033+0.02228\ttest-aft-nloglik:0.82766+0.09315\n",
      "[200]\ttrain-aft-nloglik:0.37527+0.00570\ttest-aft-nloglik:0.72806+0.08683\n",
      "[300]\ttrain-aft-nloglik:0.32436+0.00008\ttest-aft-nloglik:0.71380+0.07985\n",
      "[400]\ttrain-aft-nloglik:0.30666+0.00267\ttest-aft-nloglik:0.71832+0.07864\n",
      "[401]\ttrain-aft-nloglik:0.30655+0.00269\ttest-aft-nloglik:0.71835+0.07859\n",
      "[0]\ttrain-aft-nloglik:1.26976+0.06230\ttest-aft-nloglik:1.27411+0.06340\n",
      "[100]\ttrain-aft-nloglik:0.54116+0.02280\ttest-aft-nloglik:0.83787+0.09713\n",
      "[200]\ttrain-aft-nloglik:0.36723+0.00762\ttest-aft-nloglik:0.74333+0.09990\n",
      "[300]\ttrain-aft-nloglik:0.31797+0.00145\ttest-aft-nloglik:0.72321+0.09114\n",
      "[400]\ttrain-aft-nloglik:0.30146+0.00115\ttest-aft-nloglik:0.72577+0.08681\n",
      "[426]\ttrain-aft-nloglik:0.29898+0.00163\ttest-aft-nloglik:0.72694+0.08619\n",
      "[0]\ttrain-aft-nloglik:1.26975+0.06229\ttest-aft-nloglik:1.27411+0.06339\n",
      "[100]\ttrain-aft-nloglik:0.53941+0.02381\ttest-aft-nloglik:0.83907+0.09822\n",
      "[200]\ttrain-aft-nloglik:0.36512+0.00835\ttest-aft-nloglik:0.74504+0.09837\n",
      "[300]\ttrain-aft-nloglik:0.31614+0.00196\ttest-aft-nloglik:0.72865+0.09098\n",
      "[400]\ttrain-aft-nloglik:0.30030+0.00085\ttest-aft-nloglik:0.73243+0.08767\n",
      "[414]\ttrain-aft-nloglik:0.29899+0.00117\ttest-aft-nloglik:0.73303+0.08743\n",
      "[0]\ttrain-aft-nloglik:1.26975+0.06229\ttest-aft-nloglik:1.27411+0.06339\n",
      "[100]\ttrain-aft-nloglik:0.53928+0.02395\ttest-aft-nloglik:0.83903+0.09820\n",
      "[200]\ttrain-aft-nloglik:0.36487+0.00822\ttest-aft-nloglik:0.74593+0.09885\n",
      "[300]\ttrain-aft-nloglik:0.31581+0.00193\ttest-aft-nloglik:0.73075+0.09013\n",
      "[400]\ttrain-aft-nloglik:0.29992+0.00065\ttest-aft-nloglik:0.73504+0.08597\n",
      "[409]\ttrain-aft-nloglik:0.29905+0.00086\ttest-aft-nloglik:0.73530+0.08557\n",
      "[0]\ttrain-aft-nloglik:1.14692+0.05773\ttest-aft-nloglik:1.18664+0.06812\n",
      "[100]\ttrain-aft-nloglik:0.28898+0.00361\ttest-aft-nloglik:0.72848+0.07670\n",
      "[130]\ttrain-aft-nloglik:0.28787+0.00350\ttest-aft-nloglik:0.73378+0.07538\n",
      "[0]\ttrain-aft-nloglik:1.14537+0.05742\ttest-aft-nloglik:1.18845+0.06779\n",
      "[100]\ttrain-aft-nloglik:0.28824+0.00357\ttest-aft-nloglik:0.74243+0.07571\n",
      "[129]\ttrain-aft-nloglik:0.28736+0.00353\ttest-aft-nloglik:0.75109+0.07331\n",
      "[0]\ttrain-aft-nloglik:1.14531+0.05737\ttest-aft-nloglik:1.18851+0.06775\n",
      "[100]\ttrain-aft-nloglik:0.28787+0.00349\ttest-aft-nloglik:0.74667+0.07136\n",
      "[130]\ttrain-aft-nloglik:0.28709+0.00355\ttest-aft-nloglik:0.75483+0.06876\n",
      "[0]\ttrain-aft-nloglik:1.14531+0.05737\ttest-aft-nloglik:1.18851+0.06775\n",
      "[100]\ttrain-aft-nloglik:0.28778+0.00347\ttest-aft-nloglik:0.74728+0.07525\n",
      "[130]\ttrain-aft-nloglik:0.28700+0.00357\ttest-aft-nloglik:0.75582+0.07347\n",
      "[0]\ttrain-aft-nloglik:1.02250+0.05298\ttest-aft-nloglik:1.10131+0.07216\n",
      "[100]\ttrain-aft-nloglik:0.28661+0.00355\ttest-aft-nloglik:0.77039+0.06167\n",
      "[112]\ttrain-aft-nloglik:0.28639+0.00359\ttest-aft-nloglik:0.77390+0.06037\n",
      "[0]\ttrain-aft-nloglik:1.01940+0.05230\ttest-aft-nloglik:1.10462+0.07175\n",
      "[100]\ttrain-aft-nloglik:0.28633+0.00357\ttest-aft-nloglik:0.75418+0.08592\n",
      "[112]\ttrain-aft-nloglik:0.28620+0.00358\ttest-aft-nloglik:0.75674+0.08544\n",
      "[0]\ttrain-aft-nloglik:1.01929+0.05222\ttest-aft-nloglik:1.10473+0.07169\n",
      "[100]\ttrain-aft-nloglik:0.28625+0.00362\ttest-aft-nloglik:0.75798+0.08960\n",
      "[118]\ttrain-aft-nloglik:0.28607+0.00363\ttest-aft-nloglik:0.76195+0.08949\n",
      "[0]\ttrain-aft-nloglik:1.01929+0.05222\ttest-aft-nloglik:1.10473+0.07169\n",
      "[100]\ttrain-aft-nloglik:0.28620+0.00364\ttest-aft-nloglik:0.75178+0.07724\n",
      "[120]\ttrain-aft-nloglik:0.28600+0.00365\ttest-aft-nloglik:0.75741+0.07670\n",
      "[0]\ttrain-aft-nloglik:1.27039\n",
      "[100]\ttrain-aft-nloglik:0.56705\n",
      "[200]\ttrain-aft-nloglik:0.39236\n",
      "[300]\ttrain-aft-nloglik:0.33708\n",
      "[400]\ttrain-aft-nloglik:0.31520\n",
      "[500]\ttrain-aft-nloglik:0.30595\n",
      "[600]\ttrain-aft-nloglik:0.30207\n",
      "[700]\ttrain-aft-nloglik:0.29955\n",
      "[800]\ttrain-aft-nloglik:0.29741\n",
      "[900]\ttrain-aft-nloglik:0.29551\n",
      "[1000]\ttrain-aft-nloglik:0.29401\n",
      "[1100]\ttrain-aft-nloglik:0.29282\n",
      "[1200]\ttrain-aft-nloglik:0.29178\n",
      "[1300]\ttrain-aft-nloglik:0.29099\n",
      "[1400]\ttrain-aft-nloglik:0.29034\n",
      "[1500]\ttrain-aft-nloglik:0.28981\n",
      "[1600]\ttrain-aft-nloglik:0.28943\n",
      "[1700]\ttrain-aft-nloglik:0.28911\n",
      "[1800]\ttrain-aft-nloglik:0.28877\n",
      "[1900]\ttrain-aft-nloglik:0.28845\n",
      "[2000]\ttrain-aft-nloglik:0.28825\n",
      "[2100]\ttrain-aft-nloglik:0.28806\n",
      "[2200]\ttrain-aft-nloglik:0.28788\n",
      "[2300]\ttrain-aft-nloglik:0.28773\n",
      "[2400]\ttrain-aft-nloglik:0.28759\n",
      "[2500]\ttrain-aft-nloglik:0.28745\n",
      "[2600]\ttrain-aft-nloglik:0.28733\n",
      "[2700]\ttrain-aft-nloglik:0.28721\n",
      "[2800]\ttrain-aft-nloglik:0.28712\n",
      "[2900]\ttrain-aft-nloglik:0.28705\n",
      "[3000]\ttrain-aft-nloglik:0.28697\n",
      "[3100]\ttrain-aft-nloglik:0.28690\n",
      "[3200]\ttrain-aft-nloglik:0.28684\n",
      "[3300]\ttrain-aft-nloglik:0.28678\n",
      "[3400]\ttrain-aft-nloglik:0.28672\n",
      "[3500]\ttrain-aft-nloglik:0.28666\n",
      "[3600]\ttrain-aft-nloglik:0.28659\n",
      "[3700]\ttrain-aft-nloglik:0.28654\n",
      "[3800]\ttrain-aft-nloglik:0.28649\n",
      "[3900]\ttrain-aft-nloglik:0.28645\n",
      "[4000]\ttrain-aft-nloglik:0.28640\n",
      "[4100]\ttrain-aft-nloglik:0.28637\n",
      "[4200]\ttrain-aft-nloglik:0.28633\n",
      "[4300]\ttrain-aft-nloglik:0.28629\n",
      "[4400]\ttrain-aft-nloglik:0.28626\n",
      "[4500]\ttrain-aft-nloglik:0.28623\n",
      "[4600]\ttrain-aft-nloglik:0.28620\n",
      "[4700]\ttrain-aft-nloglik:0.28617\n",
      "[4800]\ttrain-aft-nloglik:0.28614\n",
      "[4900]\ttrain-aft-nloglik:0.28611\n",
      "[5000]\ttrain-aft-nloglik:0.28609\n",
      "[5100]\ttrain-aft-nloglik:0.28607\n",
      "[5200]\ttrain-aft-nloglik:0.28605\n",
      "[5300]\ttrain-aft-nloglik:0.28603\n",
      "[5400]\ttrain-aft-nloglik:0.28601\n",
      "[5500]\ttrain-aft-nloglik:0.28599\n",
      "[5600]\ttrain-aft-nloglik:0.28598\n",
      "[5700]\ttrain-aft-nloglik:0.28596\n",
      "[5800]\ttrain-aft-nloglik:0.28595\n",
      "[5900]\ttrain-aft-nloglik:0.28593\n",
      "[6000]\ttrain-aft-nloglik:0.28592\n",
      "[6100]\ttrain-aft-nloglik:0.28590\n",
      "[6200]\ttrain-aft-nloglik:0.28589\n",
      "[6300]\ttrain-aft-nloglik:0.28588\n",
      "[6400]\ttrain-aft-nloglik:0.28587\n",
      "[6500]\ttrain-aft-nloglik:0.28585\n",
      "[6600]\ttrain-aft-nloglik:0.28584\n",
      "[6700]\ttrain-aft-nloglik:0.28583\n",
      "[6800]\ttrain-aft-nloglik:0.28582\n",
      "[6900]\ttrain-aft-nloglik:0.28581\n",
      "[7000]\ttrain-aft-nloglik:0.28580\n",
      "[7100]\ttrain-aft-nloglik:0.28580\n",
      "[7200]\ttrain-aft-nloglik:0.28579\n",
      "[7300]\ttrain-aft-nloglik:0.28578\n",
      "[7400]\ttrain-aft-nloglik:0.28577\n",
      "[7500]\ttrain-aft-nloglik:0.28577\n",
      "[7600]\ttrain-aft-nloglik:0.28576\n",
      "[7700]\ttrain-aft-nloglik:0.28575\n",
      "[7800]\ttrain-aft-nloglik:0.28575\n",
      "[7900]\ttrain-aft-nloglik:0.28574\n",
      "[8000]\ttrain-aft-nloglik:0.28573\n",
      "[8100]\ttrain-aft-nloglik:0.28572\n",
      "[8200]\ttrain-aft-nloglik:0.28571\n",
      "[8300]\ttrain-aft-nloglik:0.28570\n",
      "[8400]\ttrain-aft-nloglik:0.28570\n",
      "[8500]\ttrain-aft-nloglik:0.28569\n",
      "[8600]\ttrain-aft-nloglik:0.28569\n",
      "[8700]\ttrain-aft-nloglik:0.28568\n",
      "[8800]\ttrain-aft-nloglik:0.28567\n",
      "[8900]\ttrain-aft-nloglik:0.28567\n",
      "[9000]\ttrain-aft-nloglik:0.28566\n",
      "[9100]\ttrain-aft-nloglik:0.28565\n",
      "[9200]\ttrain-aft-nloglik:0.28565\n",
      "[9300]\ttrain-aft-nloglik:0.28564\n",
      "[9400]\ttrain-aft-nloglik:0.28564\n",
      "[9500]\ttrain-aft-nloglik:0.28563\n",
      "[9600]\ttrain-aft-nloglik:0.28563\n",
      "[9700]\ttrain-aft-nloglik:0.28562\n",
      "[9800]\ttrain-aft-nloglik:0.28562\n",
      "[9900]\ttrain-aft-nloglik:0.28562\n",
      "[9999]\ttrain-aft-nloglik:0.28561\n",
      "[0]\ttrain-aft-nloglik:1.44017+0.00563\ttest-aft-nloglik:1.44448+0.00435\n",
      "[100]\ttrain-aft-nloglik:0.57219+0.01473\ttest-aft-nloglik:0.82568+0.05133\n",
      "[200]\ttrain-aft-nloglik:0.36866+0.01659\ttest-aft-nloglik:0.71011+0.05993\n",
      "[300]\ttrain-aft-nloglik:0.31230+0.01839\ttest-aft-nloglik:0.68809+0.07167\n",
      "[400]\ttrain-aft-nloglik:0.29346+0.01957\ttest-aft-nloglik:0.69078+0.08470\n",
      "[442]\ttrain-aft-nloglik:0.28947+0.01984\ttest-aft-nloglik:0.69430+0.08924\n",
      "[0]\ttrain-aft-nloglik:1.44008+0.00570\ttest-aft-nloglik:1.44459+0.00433\n",
      "[100]\ttrain-aft-nloglik:0.56691+0.01141\ttest-aft-nloglik:0.82802+0.04894\n",
      "[200]\ttrain-aft-nloglik:0.36501+0.01528\ttest-aft-nloglik:0.71857+0.06234\n",
      "[300]\ttrain-aft-nloglik:0.30937+0.01770\ttest-aft-nloglik:0.69321+0.07033\n",
      "[400]\ttrain-aft-nloglik:0.29100+0.01914\ttest-aft-nloglik:0.69216+0.07488\n",
      "[477]\ttrain-aft-nloglik:0.28497+0.01977\ttest-aft-nloglik:0.70470+0.08011\n",
      "[0]\ttrain-aft-nloglik:1.44008+0.00570\ttest-aft-nloglik:1.44459+0.00433\n",
      "[100]\ttrain-aft-nloglik:0.56508+0.01023\ttest-aft-nloglik:0.83390+0.04578\n",
      "[200]\ttrain-aft-nloglik:0.36429+0.01519\ttest-aft-nloglik:0.71472+0.06834\n",
      "[300]\ttrain-aft-nloglik:0.30923+0.01782\ttest-aft-nloglik:0.69613+0.08117\n",
      "[400]\ttrain-aft-nloglik:0.29099+0.01943\ttest-aft-nloglik:0.68882+0.08144\n",
      "[461]\ttrain-aft-nloglik:0.28587+0.01976\ttest-aft-nloglik:0.69997+0.08383\n",
      "[0]\ttrain-aft-nloglik:1.44008+0.00570\ttest-aft-nloglik:1.44459+0.00433\n",
      "[100]\ttrain-aft-nloglik:0.56476+0.01032\ttest-aft-nloglik:0.83468+0.04644\n",
      "[200]\ttrain-aft-nloglik:0.36444+0.01535\ttest-aft-nloglik:0.71375+0.06658\n",
      "[300]\ttrain-aft-nloglik:0.30904+0.01813\ttest-aft-nloglik:0.69331+0.07789\n",
      "[400]\ttrain-aft-nloglik:0.29081+0.01966\ttest-aft-nloglik:0.69629+0.08971\n",
      "[427]\ttrain-aft-nloglik:0.28825+0.01987\ttest-aft-nloglik:0.69987+0.09311\n",
      "[0]\ttrain-aft-nloglik:1.28900+0.00264\ttest-aft-nloglik:1.33155+0.00975\n",
      "[100]\ttrain-aft-nloglik:0.27810+0.02091\ttest-aft-nloglik:0.75033+0.11670\n",
      "[131]\ttrain-aft-nloglik:0.27686+0.02084\ttest-aft-nloglik:0.76770+0.12889\n",
      "[0]\ttrain-aft-nloglik:1.28810+0.00326\ttest-aft-nloglik:1.33257+0.00983\n",
      "[100]\ttrain-aft-nloglik:0.27726+0.02086\ttest-aft-nloglik:0.74781+0.10217\n",
      "[129]\ttrain-aft-nloglik:0.27638+0.02079\ttest-aft-nloglik:0.76338+0.11008\n",
      "[0]\ttrain-aft-nloglik:1.28810+0.00326\ttest-aft-nloglik:1.33257+0.00983\n",
      "[100]\ttrain-aft-nloglik:0.27711+0.02083\ttest-aft-nloglik:0.75195+0.12920\n",
      "[129]\ttrain-aft-nloglik:0.27625+0.02076\ttest-aft-nloglik:0.76870+0.13947\n",
      "[0]\ttrain-aft-nloglik:1.28810+0.00326\ttest-aft-nloglik:1.33257+0.00983\n",
      "[100]\ttrain-aft-nloglik:0.27713+0.02080\ttest-aft-nloglik:0.75270+0.13554\n",
      "[130]\ttrain-aft-nloglik:0.27624+0.02075\ttest-aft-nloglik:0.77024+0.14691\n",
      "[0]\ttrain-aft-nloglik:1.13639+0.00048\ttest-aft-nloglik:1.22034+0.02433\n",
      "[100]\ttrain-aft-nloglik:0.27568+0.02073\ttest-aft-nloglik:0.79044+0.13051\n",
      "[113]\ttrain-aft-nloglik:0.27547+0.02068\ttest-aft-nloglik:0.79889+0.13387\n",
      "[0]\ttrain-aft-nloglik:1.13454+0.00068\ttest-aft-nloglik:1.22204+0.02421\n",
      "[100]\ttrain-aft-nloglik:0.27544+0.02069\ttest-aft-nloglik:0.79216+0.14518\n",
      "[116]\ttrain-aft-nloglik:0.27524+0.02067\ttest-aft-nloglik:0.80267+0.15034\n",
      "[0]\ttrain-aft-nloglik:1.13454+0.00068\ttest-aft-nloglik:1.22204+0.02421\n",
      "[100]\ttrain-aft-nloglik:0.27534+0.02062\ttest-aft-nloglik:0.79588+0.16041\n",
      "[112]\ttrain-aft-nloglik:0.27521+0.02062\ttest-aft-nloglik:0.80399+0.16425\n",
      "[0]\ttrain-aft-nloglik:1.13454+0.00068\ttest-aft-nloglik:1.22204+0.02421\n",
      "[100]\ttrain-aft-nloglik:0.27532+0.02064\ttest-aft-nloglik:0.79890+0.15329\n",
      "[115]\ttrain-aft-nloglik:0.27516+0.02063\ttest-aft-nloglik:0.80823+0.15878\n",
      "[0]\ttrain-aft-nloglik:1.28651\n",
      "[100]\ttrain-aft-nloglik:0.27661\n",
      "[200]\ttrain-aft-nloglik:0.27515\n",
      "[300]\ttrain-aft-nloglik:0.27480\n",
      "[400]\ttrain-aft-nloglik:0.27465\n",
      "[500]\ttrain-aft-nloglik:0.27458\n",
      "[600]\ttrain-aft-nloglik:0.27453\n",
      "[700]\ttrain-aft-nloglik:0.27450\n",
      "[800]\ttrain-aft-nloglik:0.27447\n",
      "[900]\ttrain-aft-nloglik:0.27446\n",
      "[1000]\ttrain-aft-nloglik:0.27444\n",
      "[1100]\ttrain-aft-nloglik:0.27443\n",
      "[1200]\ttrain-aft-nloglik:0.27442\n",
      "[1300]\ttrain-aft-nloglik:0.27441\n",
      "[1400]\ttrain-aft-nloglik:0.27441\n",
      "[1500]\ttrain-aft-nloglik:0.27440\n",
      "[1600]\ttrain-aft-nloglik:0.27440\n",
      "[1700]\ttrain-aft-nloglik:0.27439\n",
      "[1800]\ttrain-aft-nloglik:0.27439\n",
      "[1900]\ttrain-aft-nloglik:0.27439\n",
      "[2000]\ttrain-aft-nloglik:0.27439\n",
      "[2100]\ttrain-aft-nloglik:0.27438\n",
      "[2200]\ttrain-aft-nloglik:0.27438\n",
      "[2300]\ttrain-aft-nloglik:0.27438\n",
      "[2400]\ttrain-aft-nloglik:0.27438\n",
      "[2500]\ttrain-aft-nloglik:0.27438\n",
      "[2600]\ttrain-aft-nloglik:0.27437\n",
      "[2700]\ttrain-aft-nloglik:0.27437\n",
      "[2800]\ttrain-aft-nloglik:0.27437\n",
      "[2900]\ttrain-aft-nloglik:0.27437\n",
      "[3000]\ttrain-aft-nloglik:0.27437\n",
      "[3100]\ttrain-aft-nloglik:0.27437\n",
      "[3200]\ttrain-aft-nloglik:0.27437\n",
      "[3300]\ttrain-aft-nloglik:0.27437\n",
      "[3400]\ttrain-aft-nloglik:0.27437\n",
      "[3500]\ttrain-aft-nloglik:0.27437\n",
      "[3600]\ttrain-aft-nloglik:0.27437\n",
      "[3700]\ttrain-aft-nloglik:0.27437\n",
      "[3800]\ttrain-aft-nloglik:0.27437\n",
      "[3822]\ttrain-aft-nloglik:0.27437\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'objective': ['survival:aft'],\n",
    "    'eval_metric': ['aft-nloglik'],\n",
    "    'aft_loss_distribution': ['normal'],\n",
    "    'aft_loss_distribution_scale': [1],\n",
    "    'tree_method': ['hist'],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [6, 8, 10, 20]\n",
    "}\n",
    "\n",
    "def perform_cross_validation(params, dtrain):\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=10000,\n",
    "        nfold=2,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "        as_pandas=True,\n",
    "        seed=42  # Set random seed for reproducibility\n",
    "    )\n",
    "    return cv_results\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Load data\n",
    "    folds_df = pd.read_csv(f'../../training_data/{dataset}/folds.csv')\n",
    "    features_df = pd.read_csv(f'../../training_data/{dataset}/features.csv')\n",
    "    target_df = pd.read_csv(f'../../training_data/{dataset}/target.csv')\n",
    "\n",
    "    for test_fold in range(1, np.unique(folds_df['fold']).size + 1):\n",
    "        # Split data into training and test sets\n",
    "        train_ids = folds_df[folds_df['fold'] != test_fold]['sequenceID']\n",
    "        test_ids = folds_df[folds_df['fold'] == test_fold]['sequenceID']\n",
    "\n",
    "        features_df_train = features_df[features_df['sequenceID'].isin(train_ids)]\n",
    "        features_df_test = features_df[features_df['sequenceID'].isin(test_ids)]\n",
    "        target_df_train = target_df[target_df['sequenceID'].isin(train_ids)]\n",
    "\n",
    "        # Create X_train and X_test\n",
    "        X_train = features_df_train.iloc[:, 1:].to_numpy()\n",
    "        X_test = features_df_test.iloc[:, 1:].to_numpy()\n",
    "\n",
    "        # Get target bounds for training\n",
    "        y_lower_bound = np.exp(target_df_train['min.log.lambda'].to_numpy())\n",
    "        y_upper_bound = np.exp(target_df_train['max.log.lambda'].to_numpy())\n",
    "\n",
    "        # Create DMatrix with bounds\n",
    "        dtrain = xgb.DMatrix(X_train)\n",
    "        dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "        dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "        # Perform cross-validation to find the best parameters\n",
    "        best_params = None\n",
    "        best_cv_score = float('inf')\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            cv_results = perform_cross_validation(params, dtrain)\n",
    "            mean_score = cv_results['test-aft-nloglik-mean'].min()  # Minimize the log-likelihood\n",
    "\n",
    "            if mean_score < best_cv_score:\n",
    "                best_cv_score = mean_score\n",
    "                best_params = params\n",
    "\n",
    "        # Train the final model with the best parameters\n",
    "        dtrain_train = xgb.DMatrix(X_train)\n",
    "        dtrain_train.set_float_info('label_lower_bound', y_lower_bound)\n",
    "        dtrain_train.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "        params = best_params  # Use the best parameters from cross-validation\n",
    "\n",
    "        bst = xgb.train(\n",
    "            params, \n",
    "            dtrain_train, \n",
    "            num_boost_round=10000, \n",
    "            evals=[(dtrain_train, 'train')],\n",
    "            early_stopping_rounds=1000,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "\n",
    "        # Create DMatrix for prediction\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "        # Predict\n",
    "        pred_lldas_exp = bst.predict(dtest)\n",
    "\n",
    "        # Apply logarithm transformation to predictions\n",
    "        pred_lldas = np.log(pred_lldas_exp)\n",
    "\n",
    "        # Save predictions to CSV\n",
    "        lldas_df = pd.DataFrame({\n",
    "            'sequenceID': features_df_test['sequenceID'],\n",
    "            'llda': pred_lldas\n",
    "        })\n",
    "        lldas_df.to_csv(f'predictions/previous.{dataset}.{test_fold}.100.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
