{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utility_functions import get_f1_score, add_row_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"epigenomic\"\n",
    "# model = \"linear\"\n",
    "# model = 'MMIT'\n",
    "# model = 'aft_xgboost'\n",
    "model = 'mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of folds\n",
    "fold_df = pd.read_csv('training_data/' + dataset + '/folds.csv')\n",
    "n_folds = np.unique(fold_df['fold']).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_folder_path = '1.' + model + '/predictions/'\n",
    "# prediction_folder_path = \"1.\" + model + '/linear_L1reg/predictions/'\n",
    "prediction_folder_path = model + '/predictions/'\n",
    "\n",
    "# List all files in the folder\n",
    "file_names = os.listdir(prediction_folder_path)\n",
    "\n",
    "def extract_between_dots(name):\n",
    "    parts = name.rsplit('.')\n",
    "    return parts[-2]\n",
    "\n",
    "n_features_list = [extract_between_dots(name) for name in file_names]\n",
    "n_features_list = np.int64(np.unique(n_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_F1_from(dataset, test_fold, n_feature):\n",
    "    evaluation_df = pd.read_csv('training_data/' + dataset + '/evaluation.csv')\n",
    "    fold_df = pd.read_csv('training_data/' + dataset + '/folds.csv')\n",
    "    eval_df = evaluation_df[evaluation_df['sequenceID'].isin(fold_df[fold_df['fold'] == test_fold]['sequenceID'])]\n",
    "    lldas_df = pd.read_csv(model + '/predictions/' + dataset + '.' + str(test_fold) + '.' + str(n_feature) + '.csv')\n",
    "    # lldas_df = pd.read_csv('1.' + model + '/linear_unreg/predictions/' + '.' + dataset + '.' + str(test_fold) + '.' + str(n_feature) + '.csv')\n",
    "    # lldas_df = pd.read_csv('1.' + model + '/linear_L1reg/predictions/' + '.' + dataset + '.' + str(test_fold) + '.' + str(n_feature) + '.csv')\n",
    "    # lldas_df = pd.read_csv('1.' + model + '/predictions/' + '.' + dataset + '.' + str(test_fold) + '.' + str(n_feature) + '.csv')\n",
    "    return get_f1_score(eval_df, lldas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_fold in range(1, n_folds+1):\n",
    "    for n_feature in n_features_list:\n",
    "        F1 = get_F1_from(dataset, test_fold, n_feature)\n",
    "        # print(dataset, test_fold, n_feature, acc)\n",
    "        add_row_to_csv('F1_score_csvs/' + dataset + '.csv', \n",
    "                ['method', 'fold', 'F1'],\n",
    "                [model.lower() + '.' + str(n_feature), test_fold, F1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
