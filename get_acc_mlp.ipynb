{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utility_functions import get_acc, add_row_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'training_data'\n",
    "datasets = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "datasets = ['systematic']\n",
    "n_best_model = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    # Load the necessary CSV files\n",
    "    cv_df = pd.read_csv(f\"model/mlp/report_{dataset}.csv\")\n",
    "    evaluation_df = pd.read_csv(f'training_data/{dataset}/evaluation.csv')\n",
    "    fold_df = pd.read_csv(f'training_data/{dataset}/folds.csv')\n",
    "\n",
    "    for test_fold in sorted(fold_df['fold'].unique()):\n",
    "        # Filter cv_df by test_fold and test_ratio\n",
    "        df_fold = cv_df[(cv_df['test_fold'] == test_fold)]\n",
    "        \n",
    "        # Filter evaluation dataframe by sequenceID\n",
    "        eval_df = evaluation_df[evaluation_df['sequenceID'].isin(fold_df[fold_df['fold'] == test_fold]['sequenceID'])]\n",
    "        \n",
    "        # Get the top n models with the lowest val_loss\n",
    "        top_rows = df_fold.nsmallest(n_best_model, 'val_loss')\n",
    "        \n",
    "        # Initialize a list to store predictions for 'llda' from the top 4 models\n",
    "        pred_list = []\n",
    "\n",
    "        for _, row in top_rows.iterrows():\n",
    "            n_layer = row['num_layers']\n",
    "            layer_size = row['layer_size']\n",
    "            # Load the corresponding prediction CSV for each model\n",
    "            pred_df = pd.read_csv(f'model/mlp/predictions_all/{dataset}.{n_layer}layers_{layer_size}neurons_{test_fold}.csv')\n",
    "            pred_df.fillna(0, inplace=True)\n",
    "            # Append the 'llda' predictions to the list\n",
    "            pred_list.append(pred_df['llda'])\n",
    "        \n",
    "        # Calculate the average of the 'llda' predictions across the 4 models\n",
    "        final_pred = sum(pred_list) / len(pred_list)\n",
    "        \n",
    "        # Replace the 'llda' column in pred_df with the averaged predictions\n",
    "        pred_df['llda'] = final_pred\n",
    "        \n",
    "        # Calculate the accuracy using the averaged predictions\n",
    "        acc = get_acc(eval_df, pred_df)\n",
    "        \n",
    "        # Save the result to the CSV file\n",
    "        add_row_to_csv('acc_rate_csvs/' + dataset + '.csv', ['method', 'fold', 'acc'], [f'mlp', test_fold, acc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
