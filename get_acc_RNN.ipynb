{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utility_functions import get_acc, add_row_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'systematic'\n",
    "model = 'gru'\n",
    "n_best_models = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.read_csv(f\"model/RNN/report_{dataset}_{model}.csv\")\n",
    "evaluation_df = pd.read_csv('training_data/' + dataset + '/evaluation.csv')\n",
    "fold_df = pd.read_csv('training_data/' + dataset + '/folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_fold in sorted(fold_df['fold'].unique()):\n",
    "    # Select the rows corresponding to the current fold\n",
    "    df_fold = cv_df[cv_df['test_fold'] == test_fold]\n",
    "    \n",
    "    # Select evaluation dataframe for the fold based on sequenceID\n",
    "    eval_df = evaluation_df[evaluation_df['sequenceID'].isin(fold_df[fold_df['fold'] == test_fold]['sequenceID'])]\n",
    "    \n",
    "    # Get the top n rows with minimum validation loss\n",
    "    top_rows = df_fold.nsmallest(n_best_models, 'val_loss')\n",
    "\n",
    "    # Initialize an empty list to store the predictions from the n models\n",
    "    pred_list = []\n",
    "\n",
    "    for _, row in top_rows.iterrows():\n",
    "        n_layer = row['num_layers']\n",
    "        h_size = row['hidden_size']\n",
    "        # Read the predictions file for each model\n",
    "        pred_df = pd.read_csv(f'model/RNN/predictions/{model}_{dataset}_{n_layer}layers_{h_size}features_fold{test_fold}.csv')\n",
    "        pred_df.fillna(0, inplace=True)\n",
    "        # Append the predictions for 'llda' to the list\n",
    "        pred_list.append(pred_df['llda'])\n",
    "\n",
    "    # Compute the average of the n models' predictions\n",
    "    final_pred = sum(pred_list) / len(pred_list)\n",
    "    \n",
    "    # Replace 'llda' column with the averaged predictions in the first pred_df\n",
    "    pred_df['llda'] = final_pred\n",
    "    \n",
    "    # Calculate accuracy using the averaged predictions\n",
    "    acc = get_acc(eval_df, pred_df)\n",
    "    \n",
    "    # Save the accuracy to the CSV\n",
    "    add_row_to_csv('acc_rate_csvs/' + dataset + '.csv', ['method', 'fold', 'acc'], [model, test_fold, acc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
