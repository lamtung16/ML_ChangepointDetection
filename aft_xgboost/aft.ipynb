{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../training_data'\n",
    "datasets = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_feature = ['length', 'variance', 'range_value', 'sum_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aft-nloglik:0.37068\tvalid-aft-nloglik:0.84453\n",
      "[100]\ttrain-aft-nloglik:0.16032\tvalid-aft-nloglik:0.27397\n",
      "[200]\ttrain-aft-nloglik:0.09964\tvalid-aft-nloglik:0.17222\n",
      "[300]\ttrain-aft-nloglik:0.07712\tvalid-aft-nloglik:0.16689\n",
      "[400]\ttrain-aft-nloglik:0.06651\tvalid-aft-nloglik:0.18322\n",
      "[500]\ttrain-aft-nloglik:0.06188\tvalid-aft-nloglik:0.19991\n",
      "[600]\ttrain-aft-nloglik:0.05901\tvalid-aft-nloglik:0.21560\n",
      "[700]\ttrain-aft-nloglik:0.05600\tvalid-aft-nloglik:0.22863\n",
      "[800]\ttrain-aft-nloglik:0.05345\tvalid-aft-nloglik:0.24101\n",
      "[900]\ttrain-aft-nloglik:0.05147\tvalid-aft-nloglik:0.24792\n",
      "[1000]\ttrain-aft-nloglik:0.04997\tvalid-aft-nloglik:0.25213\n",
      "[1100]\ttrain-aft-nloglik:0.04834\tvalid-aft-nloglik:0.25484\n",
      "[1200]\ttrain-aft-nloglik:0.04683\tvalid-aft-nloglik:0.25778\n",
      "[1254]\ttrain-aft-nloglik:0.04609\tvalid-aft-nloglik:0.25886\n",
      "[0]\ttrain-aft-nloglik:0.35673\tvalid-aft-nloglik:0.84133\n",
      "[100]\ttrain-aft-nloglik:0.16061\tvalid-aft-nloglik:0.28480\n",
      "[200]\ttrain-aft-nloglik:0.10279\tvalid-aft-nloglik:0.17701\n",
      "[300]\ttrain-aft-nloglik:0.08186\tvalid-aft-nloglik:0.16158\n",
      "[400]\ttrain-aft-nloglik:0.07254\tvalid-aft-nloglik:0.17027\n",
      "[500]\ttrain-aft-nloglik:0.06772\tvalid-aft-nloglik:0.17954\n",
      "[600]\ttrain-aft-nloglik:0.06391\tvalid-aft-nloglik:0.18733\n",
      "[700]\ttrain-aft-nloglik:0.06004\tvalid-aft-nloglik:0.19231\n",
      "[800]\ttrain-aft-nloglik:0.05737\tvalid-aft-nloglik:0.19585\n",
      "[900]\ttrain-aft-nloglik:0.05470\tvalid-aft-nloglik:0.19902\n",
      "[1000]\ttrain-aft-nloglik:0.05281\tvalid-aft-nloglik:0.20092\n",
      "[1100]\ttrain-aft-nloglik:0.05112\tvalid-aft-nloglik:0.20308\n",
      "[1200]\ttrain-aft-nloglik:0.04963\tvalid-aft-nloglik:0.20491\n",
      "[1286]\ttrain-aft-nloglik:0.04853\tvalid-aft-nloglik:0.20674\n",
      "[0]\ttrain-aft-nloglik:0.36297\tvalid-aft-nloglik:0.86295\n",
      "[100]\ttrain-aft-nloglik:0.16456\tvalid-aft-nloglik:0.28988\n",
      "[200]\ttrain-aft-nloglik:0.10503\tvalid-aft-nloglik:0.18351\n",
      "[300]\ttrain-aft-nloglik:0.08191\tvalid-aft-nloglik:0.17670\n",
      "[400]\ttrain-aft-nloglik:0.07276\tvalid-aft-nloglik:0.19473\n",
      "[500]\ttrain-aft-nloglik:0.06699\tvalid-aft-nloglik:0.21251\n",
      "[600]\ttrain-aft-nloglik:0.06351\tvalid-aft-nloglik:0.22681\n",
      "[700]\ttrain-aft-nloglik:0.06030\tvalid-aft-nloglik:0.23711\n",
      "[800]\ttrain-aft-nloglik:0.05777\tvalid-aft-nloglik:0.24426\n",
      "[900]\ttrain-aft-nloglik:0.05527\tvalid-aft-nloglik:0.25011\n",
      "[1000]\ttrain-aft-nloglik:0.05352\tvalid-aft-nloglik:0.25545\n",
      "[1100]\ttrain-aft-nloglik:0.05156\tvalid-aft-nloglik:0.25999\n",
      "[1200]\ttrain-aft-nloglik:0.05013\tvalid-aft-nloglik:0.26593\n",
      "[1262]\ttrain-aft-nloglik:0.04929\tvalid-aft-nloglik:0.26790\n",
      "[0]\ttrain-aft-nloglik:0.36356\tvalid-aft-nloglik:0.86492\n",
      "[100]\ttrain-aft-nloglik:0.15655\tvalid-aft-nloglik:0.29070\n",
      "[200]\ttrain-aft-nloglik:0.09686\tvalid-aft-nloglik:0.18294\n",
      "[300]\ttrain-aft-nloglik:0.07505\tvalid-aft-nloglik:0.17237\n",
      "[400]\ttrain-aft-nloglik:0.06558\tvalid-aft-nloglik:0.18687\n",
      "[500]\ttrain-aft-nloglik:0.06079\tvalid-aft-nloglik:0.20154\n",
      "[600]\ttrain-aft-nloglik:0.05769\tvalid-aft-nloglik:0.21536\n",
      "[700]\ttrain-aft-nloglik:0.05500\tvalid-aft-nloglik:0.22638\n",
      "[800]\ttrain-aft-nloglik:0.05295\tvalid-aft-nloglik:0.23401\n",
      "[900]\ttrain-aft-nloglik:0.05068\tvalid-aft-nloglik:0.23856\n",
      "[1000]\ttrain-aft-nloglik:0.04909\tvalid-aft-nloglik:0.24304\n",
      "[1100]\ttrain-aft-nloglik:0.04758\tvalid-aft-nloglik:0.24592\n",
      "[1200]\ttrain-aft-nloglik:0.04606\tvalid-aft-nloglik:0.24915\n",
      "[1275]\ttrain-aft-nloglik:0.04506\tvalid-aft-nloglik:0.25078\n",
      "[0]\ttrain-aft-nloglik:0.36869\tvalid-aft-nloglik:0.82111\n",
      "[100]\ttrain-aft-nloglik:0.15976\tvalid-aft-nloglik:0.26212\n",
      "[200]\ttrain-aft-nloglik:0.09808\tvalid-aft-nloglik:0.15868\n",
      "[300]\ttrain-aft-nloglik:0.07590\tvalid-aft-nloglik:0.14866\n",
      "[400]\ttrain-aft-nloglik:0.06554\tvalid-aft-nloglik:0.15783\n",
      "[500]\ttrain-aft-nloglik:0.06120\tvalid-aft-nloglik:0.16978\n",
      "[600]\ttrain-aft-nloglik:0.05750\tvalid-aft-nloglik:0.18283\n",
      "[700]\ttrain-aft-nloglik:0.05420\tvalid-aft-nloglik:0.19268\n",
      "[800]\ttrain-aft-nloglik:0.05161\tvalid-aft-nloglik:0.19917\n",
      "[900]\ttrain-aft-nloglik:0.04931\tvalid-aft-nloglik:0.20223\n",
      "[1000]\ttrain-aft-nloglik:0.04734\tvalid-aft-nloglik:0.20494\n",
      "[1100]\ttrain-aft-nloglik:0.04587\tvalid-aft-nloglik:0.20628\n",
      "[1200]\ttrain-aft-nloglik:0.04437\tvalid-aft-nloglik:0.20810\n",
      "[1276]\ttrain-aft-nloglik:0.04354\tvalid-aft-nloglik:0.20969\n",
      "[0]\ttrain-aft-nloglik:0.35692\tvalid-aft-nloglik:0.88913\n",
      "[100]\ttrain-aft-nloglik:0.15710\tvalid-aft-nloglik:0.29165\n",
      "[200]\ttrain-aft-nloglik:0.09865\tvalid-aft-nloglik:0.17663\n",
      "[300]\ttrain-aft-nloglik:0.07728\tvalid-aft-nloglik:0.16819\n",
      "[400]\ttrain-aft-nloglik:0.06796\tvalid-aft-nloglik:0.18663\n",
      "[500]\ttrain-aft-nloglik:0.06238\tvalid-aft-nloglik:0.21003\n",
      "[600]\ttrain-aft-nloglik:0.05874\tvalid-aft-nloglik:0.22986\n",
      "[700]\ttrain-aft-nloglik:0.05591\tvalid-aft-nloglik:0.24327\n",
      "[800]\ttrain-aft-nloglik:0.05384\tvalid-aft-nloglik:0.24936\n",
      "[900]\ttrain-aft-nloglik:0.05183\tvalid-aft-nloglik:0.25420\n",
      "[1000]\ttrain-aft-nloglik:0.04999\tvalid-aft-nloglik:0.25826\n",
      "[1100]\ttrain-aft-nloglik:0.04842\tvalid-aft-nloglik:0.26273\n",
      "[1200]\ttrain-aft-nloglik:0.04700\tvalid-aft-nloglik:0.26637\n",
      "[1255]\ttrain-aft-nloglik:0.04633\tvalid-aft-nloglik:0.26736\n",
      "[0]\ttrain-aft-nloglik:27.33403\tvalid-aft-nloglik:27.48124\n",
      "[100]\ttrain-aft-nloglik:7.44068\tvalid-aft-nloglik:7.12450\n",
      "[200]\ttrain-aft-nloglik:2.00187\tvalid-aft-nloglik:2.14067\n",
      "[300]\ttrain-aft-nloglik:0.97698\tvalid-aft-nloglik:1.58216\n",
      "[400]\ttrain-aft-nloglik:0.75373\tvalid-aft-nloglik:1.67286\n",
      "[500]\ttrain-aft-nloglik:0.69069\tvalid-aft-nloglik:1.76610\n",
      "[600]\ttrain-aft-nloglik:0.66075\tvalid-aft-nloglik:1.81531\n",
      "[700]\ttrain-aft-nloglik:0.63301\tvalid-aft-nloglik:1.84225\n",
      "[800]\ttrain-aft-nloglik:0.61528\tvalid-aft-nloglik:1.86348\n",
      "[900]\ttrain-aft-nloglik:0.59363\tvalid-aft-nloglik:1.88603\n",
      "[1000]\ttrain-aft-nloglik:0.57728\tvalid-aft-nloglik:1.90561\n",
      "[1100]\ttrain-aft-nloglik:0.56654\tvalid-aft-nloglik:1.91690\n",
      "[1200]\ttrain-aft-nloglik:0.55059\tvalid-aft-nloglik:1.93121\n",
      "[1300]\ttrain-aft-nloglik:0.53791\tvalid-aft-nloglik:1.94399\n",
      "[1307]\ttrain-aft-nloglik:0.53699\tvalid-aft-nloglik:1.94528\n",
      "[0]\ttrain-aft-nloglik:27.34432\tvalid-aft-nloglik:27.49676\n",
      "[100]\ttrain-aft-nloglik:7.43643\tvalid-aft-nloglik:7.12885\n",
      "[200]\ttrain-aft-nloglik:2.01915\tvalid-aft-nloglik:2.17334\n",
      "[300]\ttrain-aft-nloglik:1.01226\tvalid-aft-nloglik:1.61410\n",
      "[400]\ttrain-aft-nloglik:0.79447\tvalid-aft-nloglik:1.67392\n",
      "[500]\ttrain-aft-nloglik:0.72903\tvalid-aft-nloglik:1.75278\n",
      "[600]\ttrain-aft-nloglik:0.69966\tvalid-aft-nloglik:1.79680\n",
      "[700]\ttrain-aft-nloglik:0.68190\tvalid-aft-nloglik:1.81571\n",
      "[800]\ttrain-aft-nloglik:0.65634\tvalid-aft-nloglik:1.83172\n",
      "[900]\ttrain-aft-nloglik:0.63346\tvalid-aft-nloglik:1.84876\n",
      "[1000]\ttrain-aft-nloglik:0.61369\tvalid-aft-nloglik:1.85974\n",
      "[1100]\ttrain-aft-nloglik:0.59357\tvalid-aft-nloglik:1.88176\n",
      "[1200]\ttrain-aft-nloglik:0.57943\tvalid-aft-nloglik:1.89466\n",
      "[1300]\ttrain-aft-nloglik:0.56991\tvalid-aft-nloglik:1.90516\n",
      "[1314]\ttrain-aft-nloglik:0.56868\tvalid-aft-nloglik:1.90672\n",
      "[0]\ttrain-aft-nloglik:27.32442\tvalid-aft-nloglik:27.47710\n",
      "[100]\ttrain-aft-nloglik:7.40271\tvalid-aft-nloglik:6.97367\n",
      "[200]\ttrain-aft-nloglik:1.98985\tvalid-aft-nloglik:2.10109\n",
      "[300]\ttrain-aft-nloglik:0.97096\tvalid-aft-nloglik:1.56889\n",
      "[400]\ttrain-aft-nloglik:0.75119\tvalid-aft-nloglik:1.64420\n",
      "[500]\ttrain-aft-nloglik:0.69269\tvalid-aft-nloglik:1.73822\n",
      "[600]\ttrain-aft-nloglik:0.65639\tvalid-aft-nloglik:1.78686\n",
      "[700]\ttrain-aft-nloglik:0.63248\tvalid-aft-nloglik:1.81670\n",
      "[800]\ttrain-aft-nloglik:0.61130\tvalid-aft-nloglik:1.83509\n",
      "[900]\ttrain-aft-nloglik:0.59394\tvalid-aft-nloglik:1.85135\n",
      "[1000]\ttrain-aft-nloglik:0.57877\tvalid-aft-nloglik:1.85919\n",
      "[1100]\ttrain-aft-nloglik:0.56517\tvalid-aft-nloglik:1.86669\n",
      "[1200]\ttrain-aft-nloglik:0.55190\tvalid-aft-nloglik:1.87614\n",
      "[1300]\ttrain-aft-nloglik:0.53955\tvalid-aft-nloglik:1.88891\n",
      "[1307]\ttrain-aft-nloglik:0.53886\tvalid-aft-nloglik:1.88984\n",
      "[0]\ttrain-aft-nloglik:27.33721\tvalid-aft-nloglik:27.50249\n",
      "[100]\ttrain-aft-nloglik:7.45245\tvalid-aft-nloglik:7.37020\n",
      "[200]\ttrain-aft-nloglik:2.00546\tvalid-aft-nloglik:2.23501\n",
      "[300]\ttrain-aft-nloglik:0.99575\tvalid-aft-nloglik:1.55521\n",
      "[400]\ttrain-aft-nloglik:0.76551\tvalid-aft-nloglik:1.56257\n",
      "[500]\ttrain-aft-nloglik:0.70433\tvalid-aft-nloglik:1.61843\n",
      "[600]\ttrain-aft-nloglik:0.67728\tvalid-aft-nloglik:1.65098\n",
      "[700]\ttrain-aft-nloglik:0.65638\tvalid-aft-nloglik:1.66623\n",
      "[800]\ttrain-aft-nloglik:0.63620\tvalid-aft-nloglik:1.67900\n",
      "[900]\ttrain-aft-nloglik:0.61990\tvalid-aft-nloglik:1.68627\n",
      "[1000]\ttrain-aft-nloglik:0.60209\tvalid-aft-nloglik:1.69203\n",
      "[1100]\ttrain-aft-nloglik:0.58709\tvalid-aft-nloglik:1.69837\n",
      "[1200]\ttrain-aft-nloglik:0.57412\tvalid-aft-nloglik:1.70746\n",
      "[1300]\ttrain-aft-nloglik:0.55797\tvalid-aft-nloglik:1.71953\n",
      "[1336]\ttrain-aft-nloglik:0.55341\tvalid-aft-nloglik:1.72353\n",
      "[0]\ttrain-aft-nloglik:27.32101\tvalid-aft-nloglik:27.46888\n",
      "[100]\ttrain-aft-nloglik:7.44351\tvalid-aft-nloglik:7.27865\n",
      "[200]\ttrain-aft-nloglik:1.99500\tvalid-aft-nloglik:2.20544\n",
      "[300]\ttrain-aft-nloglik:0.97381\tvalid-aft-nloglik:1.61194\n",
      "[400]\ttrain-aft-nloglik:0.75139\tvalid-aft-nloglik:1.67826\n",
      "[500]\ttrain-aft-nloglik:0.69551\tvalid-aft-nloglik:1.75473\n",
      "[600]\ttrain-aft-nloglik:0.66944\tvalid-aft-nloglik:1.80565\n",
      "[700]\ttrain-aft-nloglik:0.64534\tvalid-aft-nloglik:1.83270\n",
      "[800]\ttrain-aft-nloglik:0.62829\tvalid-aft-nloglik:1.84838\n",
      "[900]\ttrain-aft-nloglik:0.60349\tvalid-aft-nloglik:1.86645\n",
      "[1000]\ttrain-aft-nloglik:0.58284\tvalid-aft-nloglik:1.88839\n",
      "[1100]\ttrain-aft-nloglik:0.56641\tvalid-aft-nloglik:1.90916\n",
      "[1200]\ttrain-aft-nloglik:0.55462\tvalid-aft-nloglik:1.92496\n",
      "[1300]\ttrain-aft-nloglik:0.54334\tvalid-aft-nloglik:1.93275\n",
      "[1313]\ttrain-aft-nloglik:0.54215\tvalid-aft-nloglik:1.93372\n",
      "[0]\ttrain-aft-nloglik:27.33276\tvalid-aft-nloglik:27.52451\n",
      "[100]\ttrain-aft-nloglik:7.41019\tvalid-aft-nloglik:7.28349\n",
      "[200]\ttrain-aft-nloglik:2.00892\tvalid-aft-nloglik:2.19319\n",
      "[300]\ttrain-aft-nloglik:1.00074\tvalid-aft-nloglik:1.55803\n",
      "[400]\ttrain-aft-nloglik:0.77482\tvalid-aft-nloglik:1.60341\n",
      "[500]\ttrain-aft-nloglik:0.70618\tvalid-aft-nloglik:1.67904\n",
      "[600]\ttrain-aft-nloglik:0.67479\tvalid-aft-nloglik:1.72520\n",
      "[700]\ttrain-aft-nloglik:0.64522\tvalid-aft-nloglik:1.74599\n",
      "[800]\ttrain-aft-nloglik:0.62666\tvalid-aft-nloglik:1.76002\n",
      "[900]\ttrain-aft-nloglik:0.60318\tvalid-aft-nloglik:1.77023\n",
      "[1000]\ttrain-aft-nloglik:0.58725\tvalid-aft-nloglik:1.78559\n",
      "[1100]\ttrain-aft-nloglik:0.57182\tvalid-aft-nloglik:1.80454\n",
      "[1200]\ttrain-aft-nloglik:0.55764\tvalid-aft-nloglik:1.81966\n",
      "[1300]\ttrain-aft-nloglik:0.54699\tvalid-aft-nloglik:1.82934\n",
      "[1319]\ttrain-aft-nloglik:0.54428\tvalid-aft-nloglik:1.83186\n",
      "[0]\ttrain-aft-nloglik:0.29415\tvalid-aft-nloglik:0.88556\n",
      "[100]\ttrain-aft-nloglik:0.09972\tvalid-aft-nloglik:0.24471\n",
      "[200]\ttrain-aft-nloglik:0.04502\tvalid-aft-nloglik:0.10246\n",
      "[300]\ttrain-aft-nloglik:0.02476\tvalid-aft-nloglik:0.07230\n",
      "[400]\ttrain-aft-nloglik:0.01685\tvalid-aft-nloglik:0.07029\n",
      "[500]\ttrain-aft-nloglik:0.01290\tvalid-aft-nloglik:0.07687\n",
      "[600]\ttrain-aft-nloglik:0.01056\tvalid-aft-nloglik:0.08218\n",
      "[700]\ttrain-aft-nloglik:0.00907\tvalid-aft-nloglik:0.08748\n",
      "[800]\ttrain-aft-nloglik:0.00794\tvalid-aft-nloglik:0.09090\n",
      "[900]\ttrain-aft-nloglik:0.00694\tvalid-aft-nloglik:0.09458\n",
      "[1000]\ttrain-aft-nloglik:0.00602\tvalid-aft-nloglik:0.09715\n",
      "[1100]\ttrain-aft-nloglik:0.00531\tvalid-aft-nloglik:0.10045\n",
      "[1200]\ttrain-aft-nloglik:0.00475\tvalid-aft-nloglik:0.10352\n",
      "[1300]\ttrain-aft-nloglik:0.00429\tvalid-aft-nloglik:0.10589\n",
      "[1362]\ttrain-aft-nloglik:0.00408\tvalid-aft-nloglik:0.10706\n",
      "[0]\ttrain-aft-nloglik:0.29672\tvalid-aft-nloglik:0.86676\n",
      "[100]\ttrain-aft-nloglik:0.10296\tvalid-aft-nloglik:0.23230\n",
      "[200]\ttrain-aft-nloglik:0.04792\tvalid-aft-nloglik:0.09769\n",
      "[300]\ttrain-aft-nloglik:0.02650\tvalid-aft-nloglik:0.06942\n",
      "[400]\ttrain-aft-nloglik:0.01782\tvalid-aft-nloglik:0.06707\n",
      "[500]\ttrain-aft-nloglik:0.01361\tvalid-aft-nloglik:0.07100\n",
      "[600]\ttrain-aft-nloglik:0.01110\tvalid-aft-nloglik:0.07581\n",
      "[700]\ttrain-aft-nloglik:0.00904\tvalid-aft-nloglik:0.07981\n",
      "[800]\ttrain-aft-nloglik:0.00768\tvalid-aft-nloglik:0.08310\n",
      "[900]\ttrain-aft-nloglik:0.00680\tvalid-aft-nloglik:0.08576\n",
      "[1000]\ttrain-aft-nloglik:0.00605\tvalid-aft-nloglik:0.08814\n",
      "[1100]\ttrain-aft-nloglik:0.00536\tvalid-aft-nloglik:0.09080\n",
      "[1200]\ttrain-aft-nloglik:0.00482\tvalid-aft-nloglik:0.09372\n",
      "[1300]\ttrain-aft-nloglik:0.00440\tvalid-aft-nloglik:0.09613\n",
      "[1365]\ttrain-aft-nloglik:0.00414\tvalid-aft-nloglik:0.09790\n",
      "[0]\ttrain-aft-nloglik:0.29259\tvalid-aft-nloglik:0.92401\n",
      "[100]\ttrain-aft-nloglik:0.10184\tvalid-aft-nloglik:0.23102\n",
      "[200]\ttrain-aft-nloglik:0.04661\tvalid-aft-nloglik:0.09748\n",
      "[300]\ttrain-aft-nloglik:0.02651\tvalid-aft-nloglik:0.06903\n",
      "[400]\ttrain-aft-nloglik:0.01790\tvalid-aft-nloglik:0.06590\n",
      "[500]\ttrain-aft-nloglik:0.01291\tvalid-aft-nloglik:0.06913\n",
      "[600]\ttrain-aft-nloglik:0.01031\tvalid-aft-nloglik:0.07350\n",
      "[700]\ttrain-aft-nloglik:0.00853\tvalid-aft-nloglik:0.07707\n",
      "[800]\ttrain-aft-nloglik:0.00753\tvalid-aft-nloglik:0.07838\n",
      "[900]\ttrain-aft-nloglik:0.00666\tvalid-aft-nloglik:0.08041\n",
      "[1000]\ttrain-aft-nloglik:0.00585\tvalid-aft-nloglik:0.08275\n",
      "[1100]\ttrain-aft-nloglik:0.00515\tvalid-aft-nloglik:0.08470\n",
      "[1200]\ttrain-aft-nloglik:0.00456\tvalid-aft-nloglik:0.08666\n",
      "[1300]\ttrain-aft-nloglik:0.00412\tvalid-aft-nloglik:0.08820\n",
      "[1383]\ttrain-aft-nloglik:0.00381\tvalid-aft-nloglik:0.08971\n",
      "[0]\ttrain-aft-nloglik:0.28422\tvalid-aft-nloglik:0.88132\n",
      "[100]\ttrain-aft-nloglik:0.09772\tvalid-aft-nloglik:0.23988\n",
      "[200]\ttrain-aft-nloglik:0.04491\tvalid-aft-nloglik:0.10237\n",
      "[300]\ttrain-aft-nloglik:0.02570\tvalid-aft-nloglik:0.07425\n",
      "[400]\ttrain-aft-nloglik:0.01767\tvalid-aft-nloglik:0.07191\n",
      "[500]\ttrain-aft-nloglik:0.01347\tvalid-aft-nloglik:0.07643\n",
      "[600]\ttrain-aft-nloglik:0.01098\tvalid-aft-nloglik:0.08314\n",
      "[700]\ttrain-aft-nloglik:0.00911\tvalid-aft-nloglik:0.08830\n",
      "[800]\ttrain-aft-nloglik:0.00778\tvalid-aft-nloglik:0.09190\n",
      "[900]\ttrain-aft-nloglik:0.00678\tvalid-aft-nloglik:0.09548\n",
      "[1000]\ttrain-aft-nloglik:0.00598\tvalid-aft-nloglik:0.09882\n",
      "[1100]\ttrain-aft-nloglik:0.00529\tvalid-aft-nloglik:0.10129\n",
      "[1200]\ttrain-aft-nloglik:0.00469\tvalid-aft-nloglik:0.10362\n",
      "[1300]\ttrain-aft-nloglik:0.00423\tvalid-aft-nloglik:0.10544\n",
      "[1380]\ttrain-aft-nloglik:0.00394\tvalid-aft-nloglik:0.10661\n",
      "[0]\ttrain-aft-nloglik:0.28516\tvalid-aft-nloglik:0.86720\n",
      "[100]\ttrain-aft-nloglik:0.09980\tvalid-aft-nloglik:0.23937\n",
      "[200]\ttrain-aft-nloglik:0.04653\tvalid-aft-nloglik:0.10625\n",
      "[300]\ttrain-aft-nloglik:0.02652\tvalid-aft-nloglik:0.07625\n",
      "[400]\ttrain-aft-nloglik:0.01792\tvalid-aft-nloglik:0.07264\n",
      "[500]\ttrain-aft-nloglik:0.01384\tvalid-aft-nloglik:0.07615\n",
      "[600]\ttrain-aft-nloglik:0.01104\tvalid-aft-nloglik:0.08108\n",
      "[700]\ttrain-aft-nloglik:0.00907\tvalid-aft-nloglik:0.08538\n",
      "[800]\ttrain-aft-nloglik:0.00789\tvalid-aft-nloglik:0.08812\n",
      "[900]\ttrain-aft-nloglik:0.00694\tvalid-aft-nloglik:0.09103\n",
      "[1000]\ttrain-aft-nloglik:0.00618\tvalid-aft-nloglik:0.09364\n",
      "[1100]\ttrain-aft-nloglik:0.00547\tvalid-aft-nloglik:0.09678\n",
      "[1200]\ttrain-aft-nloglik:0.00491\tvalid-aft-nloglik:0.09954\n",
      "[1300]\ttrain-aft-nloglik:0.00447\tvalid-aft-nloglik:0.10261\n",
      "[1370]\ttrain-aft-nloglik:0.00422\tvalid-aft-nloglik:0.10399\n",
      "[0]\ttrain-aft-nloglik:0.29295\tvalid-aft-nloglik:0.83950\n",
      "[100]\ttrain-aft-nloglik:0.10118\tvalid-aft-nloglik:0.23509\n",
      "[200]\ttrain-aft-nloglik:0.04668\tvalid-aft-nloglik:0.09864\n",
      "[300]\ttrain-aft-nloglik:0.02652\tvalid-aft-nloglik:0.06777\n",
      "[400]\ttrain-aft-nloglik:0.01824\tvalid-aft-nloglik:0.06365\n",
      "[500]\ttrain-aft-nloglik:0.01362\tvalid-aft-nloglik:0.06727\n",
      "[600]\ttrain-aft-nloglik:0.01131\tvalid-aft-nloglik:0.07090\n",
      "[700]\ttrain-aft-nloglik:0.00957\tvalid-aft-nloglik:0.07374\n",
      "[800]\ttrain-aft-nloglik:0.00799\tvalid-aft-nloglik:0.07702\n",
      "[900]\ttrain-aft-nloglik:0.00679\tvalid-aft-nloglik:0.08068\n",
      "[1000]\ttrain-aft-nloglik:0.00603\tvalid-aft-nloglik:0.08304\n",
      "[1100]\ttrain-aft-nloglik:0.00539\tvalid-aft-nloglik:0.08513\n",
      "[1200]\ttrain-aft-nloglik:0.00486\tvalid-aft-nloglik:0.08721\n",
      "[1300]\ttrain-aft-nloglik:0.00443\tvalid-aft-nloglik:0.08851\n",
      "[1391]\ttrain-aft-nloglik:0.00412\tvalid-aft-nloglik:0.08899\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_child_weight': [0.001, 0.1, 1.0, 10.0, 100.0],\n",
    "    'reg_alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'reg_lambda': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'aft_loss_distribution_scale': [0.5, 0.8, 1.1, 1.4, 1.7, 2.0]\n",
    "}\n",
    "\n",
    "# Loop through datasets\n",
    "for dataset in datasets:\n",
    "    # Load data\n",
    "    folds_df = pd.read_csv(f'../training_data/{dataset}/folds.csv')\n",
    "    features_df = pd.read_csv(f'../training_data/{dataset}/inputs.csv')\n",
    "    target_df = pd.read_csv(f'../training_data/{dataset}/outputs.csv')\n",
    "\n",
    "    for test_fold in range(1, np.unique(folds_df['fold']).__len__() + 1):\n",
    "        # Split data into training and test sets\n",
    "        train_ids = folds_df[folds_df['fold'] != test_fold]['sequenceID']\n",
    "        test_ids = folds_df[folds_df['fold'] == test_fold]['sequenceID']\n",
    "\n",
    "        features_df_train = features_df[features_df['sequenceID'].isin(train_ids)]\n",
    "        features_df_test = features_df[features_df['sequenceID'].isin(test_ids)]\n",
    "        target_df_train = target_df[target_df['sequenceID'].isin(train_ids)]\n",
    "\n",
    "        # Create X_train and X_test\n",
    "        X_train = features_df_train[chosen_feature].to_numpy()\n",
    "        X_test = features_df_test[chosen_feature].to_numpy()\n",
    "\n",
    "        # Get target bounds for training\n",
    "        y_lower_bound = np.exp(target_df_train['min.log.lambda'].to_numpy())\n",
    "        y_upper_bound = np.exp(target_df_train['max.log.lambda'].to_numpy())\n",
    "\n",
    "        # Create DMatrix with bounds\n",
    "        dtrain = xgb.DMatrix(X_train)\n",
    "        dtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "        dtrain.set_float_info('label_upper_bound', y_upper_bound)\n",
    "\n",
    "        # Cross-validation for hyperparameter tuning\n",
    "        best_params = None\n",
    "        best_score = float('inf')\n",
    "\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                for min_child_weight in param_grid['min_child_weight']:\n",
    "                    for reg_alpha in param_grid['reg_alpha']:\n",
    "                        for reg_lambda in param_grid['reg_lambda']:\n",
    "                            for aft_loss_distribution_scale in param_grid['aft_loss_distribution_scale']:\n",
    "                                params = {\n",
    "                                    'objective': 'survival:aft',\n",
    "                                    'eval_metric': 'aft-nloglik',\n",
    "                                    'aft_loss_distribution': 'normal',\n",
    "                                    'aft_loss_distribution_scale': aft_loss_distribution_scale,\n",
    "                                    'tree_method': 'hist',\n",
    "                                    'learning_rate': learning_rate,\n",
    "                                    'max_depth': max_depth,\n",
    "                                    'min_child_weight': min_child_weight,\n",
    "                                    'reg_alpha': reg_alpha,\n",
    "                                    'reg_lambda': reg_lambda\n",
    "                                }\n",
    "\n",
    "                                # Perform cross-validation\n",
    "                                cv_results = xgb.cv(\n",
    "                                    params,\n",
    "                                    dtrain,\n",
    "                                    num_boost_round=10000,\n",
    "                                    nfold=5,\n",
    "                                    metrics='aft-nloglik',\n",
    "                                    seed=42,\n",
    "                                    early_stopping_rounds=1000,\n",
    "                                    verbose_eval=False\n",
    "                                )\n",
    "\n",
    "                                # Check for the best score\n",
    "                                mean_score = cv_results['test-aft-nloglik-mean'].min()\n",
    "                                if mean_score < best_score:\n",
    "                                    best_score = mean_score\n",
    "                                    best_params = params\n",
    "\n",
    "        # Train the model with the best parameters\n",
    "        bst = xgb.train(\n",
    "            best_params,\n",
    "            dtrain,\n",
    "            num_boost_round=10000,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "\n",
    "        # Create DMatrix for prediction\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "        # Predict\n",
    "        pred_lldas_exp = bst.predict(dtest)\n",
    "\n",
    "        # Apply logarithm transformation to predictions\n",
    "        pred_lldas = np.log(pred_lldas_exp)\n",
    "\n",
    "        # Save predictions to CSV\n",
    "        lldas_df = pd.DataFrame({\n",
    "            'sequenceID': features_df_test['sequenceID'],\n",
    "            'llda': pred_lldas\n",
    "        })\n",
    "        lldas_df.to_csv(f'predictions/{dataset}.{test_fold}.4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
